{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import copy"
      ],
      "metadata": {
        "id": "zpSJzvRsIPH5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 128\n",
        "T = 300  # Total diffusion steps\n",
        "\n",
        "# Device configuration\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv1rhEVuIiR4",
        "outputId": "faed5c35-f884-492a-ecb3-5f161f000444"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition (same as your original code)\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # First Conv\n",
        "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
        "        # Time embedding\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        # Extend last 2 dimensions\n",
        "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        # Add time channel\n",
        "        h = h + time_emb\n",
        "        # Second Conv\n",
        "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
        "        # Down or Upsample\n",
        "        return self.transform(h)"
      ],
      "metadata": {
        "id": "1pkC2hFCIm-N"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "4ika3hk7Ite-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleUnet(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified variant of the Unet architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        image_channels = 3\n",
        "        down_channels = (64, 128, 256, 512, 1024)\n",
        "        up_channels = (1024, 512, 256, 128, 64)\n",
        "        out_dim = 3\n",
        "        time_emb_dim = 32\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "                nn.Linear(time_emb_dim, time_emb_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        # Initial projection\n",
        "        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)\n",
        "\n",
        "        # Downsample\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \\\n",
        "                                    time_emb_dim) \\\n",
        "                    for i in range(len(down_channels)-1)])\n",
        "        # Upsample\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \\\n",
        "                                        time_emb_dim, up=True) \\\n",
        "                    for i in range(len(up_channels)-1)])\n",
        "\n",
        "        self.output = nn.Conv2d(up_channels[-1], out_dim, 1)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        # Embedd time\n",
        "        t = self.time_mlp(timestep)\n",
        "        # Initial conv\n",
        "        x = self.conv0(x)\n",
        "        # Unet\n",
        "        residual_inputs = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            residual_inputs.append(x)\n",
        "        for up in self.ups:\n",
        "            residual_x = residual_inputs.pop()\n",
        "            # Add residual x as additional channels\n",
        "            x = torch.cat((x, residual_x), dim=1)\n",
        "            x = up(x, t)\n",
        "        return self.output(x)"
      ],
      "metadata": {
        "id": "jx4ErYfqI0lV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scheduler functions\n",
        "def linear_beta_scheduler(timesteps, start=0.0001, end=0.008):\n",
        "    return torch.linspace(start, end, timesteps)\n",
        "\n",
        "def get_index_from_list(vals, t, x_shape):\n",
        "    \"\"\"\n",
        "    Returns a specific index t of a passed list of values vals\n",
        "    while considering the batch dimension.\n",
        "    \"\"\"\n",
        "    batch_size = t.shape[0]\n",
        "    out = vals.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
        "\n",
        "# Pre-compute parameters\n",
        "linear_betas = linear_beta_scheduler(T)\n",
        "linear_alphas = 1. - linear_betas\n",
        "linear_alphas_cumprod = torch.cumprod(linear_alphas, axis=0)\n",
        "linear_sqrt_alphas_cumprod = torch.sqrt(linear_alphas_cumprod)\n",
        "linear_sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - linear_alphas_cumprod)\n",
        "linear_sqrt_recip_alphas = torch.sqrt(1.0 / linear_alphas)\n",
        "linear_alphas_cumprod_prev = F.pad(linear_alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "linear_posterior_variance = linear_betas * (1. - linear_alphas_cumprod_prev) / (1. - linear_alphas_cumprod)"
      ],
      "metadata": {
        "id": "VK6HcGuPI7ss"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image processing functions\n",
        "def show_tensor_image(image):\n",
        "    reverse_transforms = transforms.Compose([\n",
        "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
        "        transforms.Lambda(lambda t: t.permute(1, 2, 0)),  # CHW to HWC\n",
        "        transforms.Lambda(lambda t: t * 255.),\n",
        "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
        "        transforms.ToPILImage(),\n",
        "    ])\n",
        "\n",
        "    # Take first image of batch if needed\n",
        "    if len(image.shape) == 4:\n",
        "        image = image[0, :, :, :]\n",
        "    return reverse_transforms(image)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_timestep(model, x, t):\n",
        "    \"\"\"\n",
        "    Calls the model to predict the noise in the image and returns\n",
        "    the denoised image.\n",
        "    \"\"\"\n",
        "    betas_t = get_index_from_list(linear_betas, t, x.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        linear_sqrt_one_minus_alphas_cumprod, t, x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = get_index_from_list(linear_sqrt_recip_alphas, t, x.shape)\n",
        "\n",
        "    # Call model (current image - noise prediction)\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "    posterior_variance_t = get_index_from_list(linear_posterior_variance, t, x.shape)\n",
        "\n",
        "    if t == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        noise = torch.randn_like(x)\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_image(model, seed=None):\n",
        "    \"\"\"\n",
        "    Generate one image from random noise using the trained Unet\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    # Start with random noise\n",
        "    img = torch.randn((1, 3, IMG_SIZE, IMG_SIZE), device=device)\n",
        "\n",
        "    # Sample through timesteps\n",
        "    for i in range(0, T)[::-1]:\n",
        "        t = torch.full((1,), i, device=device, dtype=torch.long)\n",
        "        img = sample_timestep(model, img, t)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "UFb96TXbJCXq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning functions\n",
        "def iterative_magnitude_pruning(model, sparsity):\n",
        "    \"\"\"\n",
        "    Apply iterative magnitude pruning (IMP) to the model.\n",
        "\n",
        "    Args:\n",
        "        model: The PyTorch model to prune\n",
        "        sparsity: Target sparsity level (0.0 to 1.0)\n",
        "\n",
        "    Returns:\n",
        "        Pruned model\n",
        "    \"\"\"\n",
        "    pruned_model = copy.deepcopy(model)\n",
        "\n",
        "    # Get all weight parameters\n",
        "    weights = []\n",
        "    for name, param in pruned_model.named_parameters():\n",
        "        if 'weight' in name and param.dim() > 1:  # Only prune weights in Conv and Linear layers\n",
        "            weights.append((name, param))\n",
        "\n",
        "    # Calculate the number of weights to prune\n",
        "    total_weights = sum(w[1].numel() for w in weights)\n",
        "    num_to_prune = int(total_weights * sparsity)\n",
        "\n",
        "    # Flatten all weights and get the magnitude threshold\n",
        "    all_weights = torch.cat([w[1].data.view(-1).abs() for w in weights])\n",
        "    threshold = torch.sort(all_weights)[0][num_to_prune]\n",
        "\n",
        "    # Apply pruning\n",
        "    zero_weight_count = 0\n",
        "    for name, param in weights:\n",
        "        mask = param.data.abs() > threshold\n",
        "        param.data.mul_(mask)\n",
        "        zero_weight_count += (~mask).sum().item()\n",
        "\n",
        "    print(f\"IMP Pruning: Set {zero_weight_count} weights to zero ({zero_weight_count/total_weights:.2%} sparsity)\")\n",
        "    return pruned_model"
      ],
      "metadata": {
        "id": "F5sfvnsJJL88"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hilbert_schmidt_pruning(model, sparsity):\n",
        "    \"\"\"\n",
        "    Apply Hilbert-Schmidt pruning to the model.\n",
        "\n",
        "    Args:\n",
        "        model: The PyTorch model to prune\n",
        "        sparsity: Target sparsity level (0.0 to 1.0)\n",
        "\n",
        "    Returns:\n",
        "        Pruned model\n",
        "    \"\"\"\n",
        "    pruned_model = copy.deepcopy(model)\n",
        "\n",
        "    # Get all weight parameters that can be pruned\n",
        "    weights = []\n",
        "    for name, param in pruned_model.named_parameters():\n",
        "        if 'weight' in name and param.dim() > 1:  # Only prune weights in Conv and Linear layers\n",
        "            weights.append((name, param))\n",
        "\n",
        "    # Calculate the number of weights to prune\n",
        "    total_weights = sum(w[1].numel() for w in weights)\n",
        "    num_to_prune = int(total_weights * sparsity)\n",
        "\n",
        "    # Calculate Hilbert-Schmidt norm (Frobenius norm) for each weight tensor\n",
        "    hs_norms = {}\n",
        "    for name, param in weights:\n",
        "        # For each individual weight, calculate its contribution to the Frobenius norm\n",
        "        param_norms = param.data.pow(2)\n",
        "        hs_norms[name] = param_norms\n",
        "\n",
        "    # Flatten all norm contributions\n",
        "    all_norm_contribs = torch.cat([norm.view(-1) for norm in hs_norms.values()])\n",
        "    threshold = torch.sort(all_norm_contribs)[0][num_to_prune]\n",
        "\n",
        "    # Apply pruning based on contribution to Hilbert-Schmidt norm\n",
        "    zero_weight_count = 0\n",
        "    for name, param in weights:\n",
        "        mask = hs_norms[name] > threshold\n",
        "        param.data.mul_(mask)\n",
        "        zero_weight_count += (~mask).sum().item()\n",
        "\n",
        "    print(f\"HS Pruning: Set {zero_weight_count} weights to zero ({zero_weight_count/total_weights:.2%} sparsity)\")\n",
        "    return pruned_model"
      ],
      "metadata": {
        "id": "gOSLaH1NJXqc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"Count total and non-zero parameters in the model\"\"\"\n",
        "    total_params = 0\n",
        "    nonzero_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            nparam = param.numel()\n",
        "            total_params += nparam\n",
        "            nonzero_params += (param != 0).sum().item()\n",
        "\n",
        "    return total_params, nonzero_params"
      ],
      "metadata": {
        "id": "SFEjNAC6Jdgd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, path):\n",
        "    \"\"\"Load model weights from path\"\"\"\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "znkHX7siJjz7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, output_dir, num_images=5, prefix=\"\"):\n",
        "    \"\"\"Generate multiple images and save them\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    all_images = []\n",
        "    for i in range(num_images):\n",
        "        # Use a consistent seed for each position to ensure fair comparison\n",
        "        img = generate_image(model, seed=i)\n",
        "        pil_img = show_tensor_image(img.detach().cpu())\n",
        "        all_images.append(pil_img)\n",
        "        pil_img.save(os.path.join(output_dir, f\"{prefix}_sample_{i}.png\"))\n",
        "\n",
        "    # Create a grid of images\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images*4, 4))\n",
        "    for i, (ax, img) in enumerate(zip(axes, all_images)):\n",
        "        ax.imshow(np.array(img))\n",
        "        ax.set_title(f\"Sample {i}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f\"{prefix}_grid.png\"))\n",
        "    plt.close()\n",
        "    return all_images"
      ],
      "metadata": {
        "id": "gdutqkzMJoiP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Create the model\n",
        "    model = SimpleUnet()\n",
        "\n",
        "    # Load the original model\n",
        "    original_model = load_model(model, \"model.pth\")\n",
        "\n",
        "    # Calculate and print statistics\n",
        "    total_params, nonzero_params = count_parameters(original_model)\n",
        "    print(f\"Original model: {total_params} total parameters, {nonzero_params} non-zero ({nonzero_params/total_params:.2%})\")\n",
        "\n",
        "    # Create output directory\n",
        "    output_dir = \"pruning_results\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Generate images with the original model\n",
        "    print(\"Generating images with original model...\")\n",
        "    original_images = generate_and_save_images(original_model, output_dir, num_images=5, prefix=\"original\")\n",
        "\n",
        "    # Apply different pruning methods at different sparsity levels\n",
        "    sparsity_levels = [0.25, 0.50, 0.75, 0.90]\n",
        "    pruning_methods = {\n",
        "        \"imp\": iterative_magnitude_pruning,\n",
        "        \"hs\": hilbert_schmidt_pruning\n",
        "    }\n",
        "\n",
        "    # Store all images for final grid\n",
        "    all_results = {\"original\": original_images}\n",
        "\n",
        "    for method_name, method_func in pruning_methods.items():\n",
        "        method_results = {}\n",
        "        for sparsity in sparsity_levels:\n",
        "            print(f\"Applying {method_name} pruning with {sparsity:.0%} sparsity...\")\n",
        "            pruned_model = method_func(original_model, sparsity)\n",
        "\n",
        "            # Count parameters\n",
        "            total, nonzero = count_parameters(pruned_model)\n",
        "            actual_sparsity = 1 - nonzero/total\n",
        "            print(f\"  Achieved sparsity: {actual_sparsity:.2%}\")\n",
        "\n",
        "            # Generate images with the pruned model\n",
        "            print(f\"Generating images with {method_name} pruned model ({sparsity:.0%} sparsity)...\")\n",
        "            prefix = f\"{method_name}_{int(sparsity*100)}\"\n",
        "            pruned_images = generate_and_save_images(pruned_model, output_dir, num_images=5, prefix=prefix)\n",
        "            method_results[f\"{int(sparsity*100)}%\"] = pruned_images\n",
        "\n",
        "        all_results[method_name] = method_results\n",
        "\n",
        "    # Create a comprehensive comparison grid\n",
        "    num_methods = len(pruning_methods)\n",
        "    num_sparsity = len(sparsity_levels)\n",
        "    num_samples = 5\n",
        "\n",
        "    # Fix: Change num_methods + 1 to num_methods + 2 to account for header row and original model row\n",
        "    fig, axes = plt.subplots(num_methods + 2, num_sparsity + 1,\n",
        "                             figsize=((num_sparsity + 1) * 4, (num_methods + 2) * 4))\n",
        "\n",
        "    # Set up the row and column headers\n",
        "    axes[0, 0].axis('off')\n",
        "    for i, sparsity in enumerate(sparsity_levels):\n",
        "        axes[0, i+1].set_title(f\"{int(sparsity*100)}% Sparsity\")\n",
        "        axes[0, i+1].axis('off')\n",
        "\n",
        "    # Original model (first row)\n",
        "    axes[1, 0].set_title(\"Original\")\n",
        "    axes[1, 0].axis('off')\n",
        "    for j in range(num_sparsity):\n",
        "        img = original_images[j % num_samples]\n",
        "        axes[1, j+1].imshow(np.array(img))\n",
        "        axes[1, j+1].axis('off')\n",
        "\n",
        "    # Pruned models\n",
        "    for i, method_name in enumerate(pruning_methods.keys()):\n",
        "        axes[i+2, 0].set_title(method_name.upper())\n",
        "        axes[i+2, 0].axis('off')\n",
        "\n",
        "        for j, sparsity in enumerate(sparsity_levels):\n",
        "            sparsity_key = f\"{int(sparsity*100)}%\"\n",
        "            img = all_results[method_name][sparsity_key][j % num_samples]\n",
        "            axes[i+2, j+1].imshow(np.array(img))\n",
        "            axes[i+2, j+1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, \"comprehensive_comparison.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"All results saved to {output_dir}/\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQpy_8XNJt-B",
        "outputId": "6dadad63-dffa-4a47-9742-d0a58aec2dab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model: 62438883 total parameters, 62438883 non-zero (100.00%)\n",
            "Generating images with original model...\n",
            "Applying imp pruning with 25% sparsity...\n",
            "IMP Pruning: Set 15603940 weights to zero (25.00% sparsity)\n",
            "  Achieved sparsity: 24.99%\n",
            "Generating images with imp pruned model (25% sparsity)...\n",
            "Applying imp pruning with 50% sparsity...\n",
            "IMP Pruning: Set 31207875 weights to zero (50.00% sparsity)\n",
            "  Achieved sparsity: 49.98%\n",
            "Generating images with imp pruned model (50% sparsity)...\n",
            "Applying imp pruning with 75% sparsity...\n",
            "IMP Pruning: Set 46811809 weights to zero (75.00% sparsity)\n",
            "  Achieved sparsity: 74.97%\n",
            "Generating images with imp pruned model (75% sparsity)...\n",
            "Applying imp pruning with 90% sparsity...\n",
            "IMP Pruning: Set 56174172 weights to zero (90.00% sparsity)\n",
            "  Achieved sparsity: 89.97%\n",
            "Generating images with imp pruned model (90% sparsity)...\n",
            "Applying hs pruning with 25% sparsity...\n",
            "HS Pruning: Set 15603940 weights to zero (25.00% sparsity)\n",
            "  Achieved sparsity: 24.99%\n",
            "Generating images with hs pruned model (25% sparsity)...\n",
            "Applying hs pruning with 50% sparsity...\n",
            "HS Pruning: Set 31207875 weights to zero (50.00% sparsity)\n",
            "  Achieved sparsity: 49.98%\n",
            "Generating images with hs pruned model (50% sparsity)...\n",
            "Applying hs pruning with 75% sparsity...\n",
            "HS Pruning: Set 46811809 weights to zero (75.00% sparsity)\n",
            "  Achieved sparsity: 74.97%\n",
            "Generating images with hs pruned model (75% sparsity)...\n",
            "Applying hs pruning with 90% sparsity...\n",
            "HS Pruning: Set 56174172 weights to zero (90.00% sparsity)\n",
            "  Achieved sparsity: 89.97%\n",
            "Generating images with hs pruned model (90% sparsity)...\n",
            "All results saved to pruning_results/\n"
          ]
        }
      ]
    }
  ]
}